* nix-mirror
There is an unsolved issue https://github.com/NixOS/nix/issues/2774 indirectly
related to the problems in mirroring nix binary cache due to excessive
complexity of the =nix= tool for such a simple task. Meanwhile, I started to
address the issue in a separate project.

The project not only aimed at binary cache, but also to provide a completely
offline operation for NixOS, thus downloading and serving nix fixed outputs
(i.e. tarballs and other sources).

Currently, the project contains:
- a program which downloads a binary cache for the given store-paths
- [[mirror all fixed outputs needed for a completely offline NixOS operation][notes about getting fixed outputs]] in this README

The program is not guaranteed to run in constant space as a whole, but for the
crucial part - file download. The download mechanics do not seem to be
deterministic, based on narinfo metainformation for references (dependencies of
store-paths), not nixpkgs. But at least the initial goal (solving [[https://github.com/NixOS/nix/issues/2774][the issue]] for
me) seems to be met (the result needs to be tested in a real offline
environment).

* goals
** nix binary cache mirroring
*** download
**** input
- [x] file, containing a list of store paths
  - file format as of =store-paths= from https://nixos.org/channels/
**** how
- [x] download =narinfo= for every input store-path
- [x] recursively download =narinfo= for every reference (dependency)
  - dependencies are read from =narinfo= from the field =References:=
- [x] download =*.nar.xz= taken from =URL:= field of each =narinfo=
- [x] validate downloaded =*.nar.xz= (with checksum from narinfo)

**** features
- [x] resumable downloads
  - Interrupted download should be (unless I'm mistaken) easily resumed. Since
    all partially downloaded files are stored with a temporary filename and only
    fully downloaded and valid (correct checksum) files obtain the final
    filename.

    So, either the file download results in a genuine file, either not. Thus,
    individual files download is not resumed, but already downloaded valid files
    are not redownloaded (nor contents being rechecked).

  - Every time the program is run it traverses the whole narinfo tree (it's not
    very time consuming even on NanoPi Neo2).

- [ ] ensure saved files integrity later by utilizing btrfs snapshots capability
  - Some obstacles are expected in btrfs snapshots machinery
    when manipulated as a non-superuser.
*** serve
With nginx. Nix integration is not investigated yet.

** mirror all fixed outputs needed for a completely offline NixOS operation
*** resources I used to get into this
  - https://github.com/NixOS/nixpkgs/blob/master/maintainers/scripts/find-tarballs.nix
  - https://github.com/NixOS/nixpkgs/blob/master/maintainers/scripts/copy-tarballs.pl
  - https://github.com/NixOS/nixpkgs/blob/master/maintainers/scripts/all-tarballs.nix
  - http://web.archive.org/web/20160322151426/https://nixos.org/wiki/Download_all_sources
  - https://github.com/bjornfor/nixpkgs/blob/find-all-sources/maintainers/scripts/all-sources.nix
  - https://gist.github.com/LnL7/cb4cd501695536d2d4c467d9546eaf4b
  - https://github.com/NixOS/nixpkgs/blob/master/pkgs/top-level/make-tarball.nix
*** supposed methods
**** instantiate [[https://github.com/NixOS/nixpkgs/blob/master/maintainers/scripts/find-tarballs.nix][find-tarballs.nix]] with [[https://github.com/NixOS/nixpkgs/blob/master/maintainers/scripts/all-tarballs.nix][all-tarballs.nix]] as an argument
     #+BEGIN_EXAMPLE shell
     $ nix-instantiate --readonly-mode --eval --strict --json ./maintainers/scripts/find-tarballs.nix --arg expr 'import ./maintainers/scripts/all-tarballs.nix'
     #+END_EXAMPLE
     - Produces a json array, each element of which contains: =name=, =hash=,
       original =url=, =hash= type (=sha256=, =sha1=, =sha512=, etc).
     - The way [[https://github.com/NixOS/nixpkgs/blob/master/maintainers/scripts/copy-tarballs.pl][copy-tarballs.pl]] does.
     - Omits many sources, at least fetchgit. The produced array is a subset of
       what [[instantiate all-sources.nix with all-tarballs.nix as an argument][all-sources.nix]] produces (if we could get name, hash, url, type from
       derivations).
     - Uses a ton (~8 GiB) of RAM.
**** instantiate [[https://github.com/bjornfor/nixpkgs/blob/find-all-sources/maintainers/scripts/all-sources.nix][all-sources.nix]] with [[https://github.com/NixOS/nixpkgs/blob/master/maintainers/scripts/all-tarballs.nix][all-tarballs.nix]] as an argument
     [[https://github.com/bjornfor/nixpkgs/blob/find-all-sources/maintainers/scripts/all-sources.nix][all-sources.nix]] is put into ./maintainers/scripts.
     #+BEGIN_EXAMPLE shell
     $ nix-instantiate --readonly-mode --eval --strict --json ./maintainers/scripts/all-sources.nix --arg expr 'import ./maintainers/scripts/all-tarballs.nix'
     #+END_EXAMPLE
     - Produces a json array of fixed outputs. A superset of [[instantiate find-tarballs.nix with all-tarballs.nix as an argument][find-tarballs.nix]]
       produces if converted to fixed outputs.
     - Are there any other missing fixed outputs?
     - How to download the files knowing only their fixed output name?
       =nix-store -r=?
     - Contains a few duplicates.
     - Uses a ton (~8 GiB) of RAM.
**** instantiate [[https://gist.github.com/LnL7/cb4cd501695536d2d4c467d9546eaf4b][find-fixed-outputs.nix]]
     [[https://gist.github.com/LnL7/cb4cd501695536d2d4c467d9546eaf4b][find-fixed-outputs.nix]] is put into ./maintainers/scripts.
     #+BEGIN_EXAMPLE shell
     $ nix-instantiate --eval --strict --json ./maintainers/scripts/find-fixed-outputs.nix --arg expr 'import ./maintainers/scripts/all-tarballs.nix'
     #+END_EXAMPLE
     - Produces a json array, each element of which contains: =name=, =hash=,
       =drv= (derivation name), hash =type=, =mode= (has two posssible values:
       =flat=, =recursive=).
     - Gives the most number of items out of the supposed methods. Confirmed
       that this is a superset of all-sources method! Great thanks to the
       creator!
     - Compared to all-sources method, allows to easily download using either
       =hash=, either =drv= for =store -r=.
     - Uses a ton (~8 GiB) of RAM.

* build instructions
#+BEGIN_EXAMPLE shell
$ stack build
#+END_EXAMPLE
It will automatically pick =shell.nix= configuration with pinned nixpkgs for
Nix. In order to build wihout Nix integration, I guess you'll have to append
=--no-nix= option to =stack=.

* reports
** aarch64 build
Builds and runs successfully under NixOS, but see caveats below.

As for Raspberry Pi 3 / NanoPi Neo2 building the whole project may take a ton
of time (maybe half a month) with ~4 GiB swap provided. There are lots of
packages to build as dependencies. Personally I've never completed the Cabal
dependency build on the real hardware - too few RAM. Based on my experience, it
needs at least 4 GiB (rpi3 has only 1 GiB).

So, the solution is to build under qemu virtual machine. It works fine, except
the limit of 3 GiB RAM caused by broken AHCI emulation. It takes approximately
2 days to build from scratch. All the built dependencies can be copied from
=~/.stack= to the real hardware aarch64 machine. So, you are able to build just
the source code of the project. But still it takes almost an hour on NanoPi Neo2
with 512 MiB RAM.

** downloaded binary cache stats
*** nixos-19.03.173202.31d476b8797
Git revision: 31d476b87972d8f97d67fd65e74c477b23227434.
- store paths count: 32187
  - input, taken from
    https://releases.nixos.org/nixos/19.03/nixos-19.03.173202.31d476b8797
- narinfo count: 38634
  - I haven't checked yet whether these are really all narinfos available for
    this specific nixpkgs revision
- nar count: 38093
  - lower than narinfo count because of duplicates, i.e. several
    narinfos point to the same nar file
- size
  - on disk
    - total: 72263 MiB
    - narinfos: 154 MiB
    - nars: 72109 MiB
  - apparent:
    - total: 72067 MiB
    - narinfos: 36 MiB
    - nars: 72032 MiB
- approximate time consumed: 30 hours running on NanoPi Neo2 (on my 100 Mbit
  internet).

* questions
- Does the mirror process really benefit from the =req= package (instead of
  =http-conduit=)?
  * advantages: automatic retries, sharing the same connection across requests?
  * disadvantage: =req= brings twice as more dependencies
- Dow to generate store-paths list for a specific nixpkgs commit?
- All supposed methods for downloading fixed outputs:
  - use [[https://github.com/NixOS/nixpkgs/blob/master/maintainers/scripts/all-tarballs.nix][all-tarballs.nix]] as an argument, is it the right way?
  - use a ton (~8 GiB) of RAM, have a try for hnix?
